<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Nousad Voice Experience</title>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&family=Roboto:wght@300;400;500&display=swap" rel="stylesheet">
    
    <script src="https://cdn.tailwindcss.com"></script>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

    <script type="importmap">
    {
      "imports": {
        "@google/generative-ai": "https://esm.run/@google/generative-ai"
      }
    }
    </script>

    <style>
        :root {
            --google-blue: #4285F4;
            --google-red: #DB4437;
            --google-yellow: #F4B400;
            --google-green: #0F9D58;
            --gemini-bg: #131314;
            --surface: #1E1F20;
        }

        body {
            font-family: 'Inter', sans-serif;
            background-color: var(--gemini-bg);
            color: #E3E3E3;
            overflow: hidden; /* Prevent scrolling in voice mode */
        }

        /* --- Google Voice Blob Animation --- */
        .google-blob {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            background: linear-gradient(135deg, var(--google-blue), var(--google-red));
            position: relative;
            filter: blur(2px);
            box-shadow: 0 0 60px rgba(66, 133, 244, 0.4);
            animation: breathe 4s infinite ease-in-out;
            transition: all 0.5s ease;
        }

        .google-blob::after {
            content: '';
            position: absolute;
            inset: -10px;
            border-radius: 50%;
            background: linear-gradient(45deg, var(--google-yellow), var(--google-green));
            opacity: 0.6;
            filter: blur(10px);
            z-index: -1;
            animation: rotate 6s infinite linear;
        }

        /* States */
        .blob-listening {
            transform: scale(1.1);
            filter: blur(0px);
            box-shadow: 0 0 80px rgba(255, 255, 255, 0.2);
            animation: pulse-listen 1.5s infinite ease-in-out;
        }

        .blob-speaking {
            transform: scale(1.3);
            background: linear-gradient(135deg, #FFF, #A8C7FA);
            box-shadow: 0 0 100px rgba(168, 199, 250, 0.6);
            animation: speak-jiggle 0.4s infinite alternate;
        }

        .blob-processing {
            animation: rotate 1s infinite linear;
            background: conic-gradient(from 0deg, var(--google-blue), var(--google-red), var(--google-yellow), var(--google-green), var(--google-blue));
        }

        @keyframes breathe { 0%, 100% { transform: scale(1); } 50% { transform: scale(1.05); } }
        @keyframes rotate { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
        @keyframes pulse-listen { 0% { transform: scale(1); opacity: 0.8; } 50% { transform: scale(1.1); opacity: 1; } 100% { transform: scale(1); opacity: 0.8; } }
        @keyframes speak-jiggle { 0% { transform: scale(1.3) skewX(-2deg); } 100% { transform: scale(1.35) skewX(2deg); } }

        /* Transitions */
        .fade-enter { opacity: 0; transform: translateY(20px); }
        .fade-enter-active { opacity: 1; transform: translateY(0); transition: opacity 0.4s, transform 0.4s; }
        .fade-exit { opacity: 1; }
        .fade-exit-active { opacity: 0; transition: opacity 0.3s; }

        /* Hide Scrollbar */
        .no-scrollbar::-webkit-scrollbar { display: none; }
    </style>
</head>
<body class="h-screen w-screen flex flex-col items-center justify-center relative">

    <div id="start-screen" class="flex flex-col items-center gap-8 z-10 transition-all duration-500">
        <h1 class="text-4xl font-normal tracking-tight bg-clip-text text-transparent bg-gradient-to-r from-blue-400 to-red-400">
            Nousad Voice
        </h1>
        <p class="text-gray-400 text-sm">Tap the microphone to start</p>
        <button id="btn-start" class="w-16 h-16 rounded-full bg-[#1E1F20] hover:bg-[#2d2e30] flex items-center justify-center shadow-lg border border-white/10 transition-all active:scale-95 group">
            <span class="material-icons-round text-2xl text-google-blue">
                <i class="fas fa-microphone text-2xl text-[#4285F4] group-hover:text-white transition-colors"></i>
            </span>
        </button>
    </div>

    <div id="voice-overlay" class="fixed inset-0 bg-[#131314] z-50 flex flex-col items-center justify-center opacity-0 pointer-events-none transition-opacity duration-500">
        
        <div class="absolute top-6 right-6">
            <button id="btn-close" class="w-10 h-10 rounded-full bg-white/5 hover:bg-white/10 flex items-center justify-center text-white/70 hover:text-white transition-all">
                <i class="fas fa-times"></i>
            </button>
        </div>

        <div class="flex-1 flex flex-col items-center justify-center w-full max-w-2xl px-6 relative">
            
            <div id="orb-container" class="relative mb-12">
                <div id="orb" class="google-blob"></div>
            </div>

            <div id="status-indicator" class="text-sm font-medium tracking-widest text-white/40 uppercase mb-4 opacity-0 transition-opacity">
                Listening...
            </div>

            <div id="user-captions" class="text-2xl md:text-3xl font-light text-center text-white leading-relaxed min-h-[80px] transition-all">
                </div>
            
        </div>

        <div class="absolute bottom-8 flex items-center gap-2 opacity-30">
            <i class="fas fa-sparkles text-xs"></i>
            <span class="text-xs font-medium tracking-widest">Developed by Nousad</span>
        </div>
    </div>

    <script type="module">
        import { GoogleGenerativeAI } from "@google/generative-ai";

        // --- Config ---
        // REPLACE WITH YOUR KEY
        const API_KEY = "AIzaSyCA55VTeGj99g3Gc59c0v-Fd3KASTrVqq0"; 
        
        const SYSTEM_PROMPT = "You are Nousad AI, a helpful AI from Google. You are in a voice-only mode. Keep your answers extremely concise, conversational, and natural. Do not use markdown, lists, or code blocks. Speak as if talking to a friend.";

        // --- DOM ---
        const els = {
            startScreen: document.getElementById('start-screen'),
            overlay: document.getElementById('voice-overlay'),
            btnStart: document.getElementById('btn-start'),
            btnClose: document.getElementById('btn-close'),
            orb: document.getElementById('orb'),
            captions: document.getElementById('user-captions'),
            status: document.getElementById('status-indicator')
        };

        // --- State ---
        const state = {
            genAI: null,
            model: null,
            chat: null,
            recognition: null,
            synth: window.speechSynthesis,
            isActive: false,
            isProcessing: false,
            voices: []
        };

        // --- Init ---
        async function init() {
            // Setup AI
            state.genAI = new GoogleGenerativeAI(API_KEY);
            // Fallback to stable model to avoid 404
            state.model = state.genAI.getGenerativeModel({ model: "gemini-3-flash-preview" });
            
            state.chat = state.model.startChat({
                history: [
                    { role: "user", parts: [{ text: SYSTEM_PROMPT }] },
                    { role: "model", parts: [{ text: "I'm ready." }] }
                ]
            });

            // Setup Speech Rec
            if ('webkitSpeechRecognition' in window) {
                state.recognition = new webkitSpeechRecognition();
                state.recognition.continuous = true; // Keep listening
                state.recognition.interimResults = true; // For live captions
                state.recognition.lang = 'en-US';

                state.recognition.onstart = () => {
                    updateStatus('listening');
                };

                state.recognition.onresult = (event) => {
                    // If AI is speaking, stop it when user interrupts
                    if (state.synth.speaking) state.synth.cancel();

                    let interim = '';
                    let final = '';

                    for (let i = event.resultIndex; i < event.results.length; ++i) {
                        if (event.results[i].isFinal) {
                            final += event.results[i][0].transcript;
                            processCommand(final);
                        } else {
                            interim += event.results[i][0].transcript;
                        }
                    }
                    
                    if (interim) {
                        els.captions.innerText = interim;
                        els.captions.style.opacity = '1';
                    }
                };

                state.recognition.onend = () => {
                    if (state.isActive && !state.isProcessing && !state.synth.speaking) {
                        state.recognition.start();
                    }
                };
            } else {
                alert("Browser does not support Speech API. Please use Chrome.");
            }

            // Load Voices
            window.speechSynthesis.onvoiceschanged = () => {
                state.voices = window.speechSynthesis.getVoices();
            };
        }

        // --- Core Logic ---

        async function processCommand(text) {
            if (!text.trim()) return;
            
            // 1. Update UI to Processing
            state.isProcessing = true;
            state.recognition.stop(); // Stop listening while thinking
            updateStatus('processing');
            els.captions.innerText = text; // Show final user text
            
            try {
                // 2. Send to Nousad
                const result = await state.chat.sendMessage(text);
                const response = result.response.text();

                // 3. Speak Response
                speak(response);
            } catch (err) {
                console.error(err);
                updateStatus('error');
                state.isProcessing = false;
                state.recognition.start();
            }
        }

        function speak(text) {
            // Clean text (remove asterisks, markdown)
            const cleanText = text.replace(/[*#]/g, '');
            
            const utterance = new SpeechSynthesisUtterance(cleanText);
            
            // Select a good voice (prefer Google US English)
            const preferredVoice = state.voices.find(v => v.name.includes('Google US English')) || state.voices[0];
            if (preferredVoice) utterance.voice = preferredVoice;

            utterance.rate = 1.0;
            utterance.pitch = 1.0;

            utterance.onstart = () => {
                updateStatus('speaking');
                // Clear user captions so focus is on the voice/orb
                els.captions.style.opacity = '0.3'; 
            };

            utterance.onend = () => {
                state.isProcessing = false;
                updateStatus('listening');
                els.captions.innerText = "";
                els.captions.style.opacity = '1';
                if(state.isActive) state.recognition.start();
            };

            state.synth.speak(utterance);
        }

        // --- UI Handling ---

        function updateStatus(mode) {
            // Reset classes
            els.orb.className = 'google-blob';
            els.status.style.opacity = '0';

            switch(mode) {
                case 'listening':
                    els.orb.classList.add('blob-listening');
                    els.status.innerText = "Listening";
                    els.status.style.opacity = '1';
                    break;
                case 'processing':
                    els.orb.classList.add('blob-processing');
                    els.status.innerText = "Thinking";
                    els.status.style.opacity = '1';
                    break;
                case 'speaking':
                    els.orb.classList.add('blob-speaking');
                    els.status.innerText = "Speaking";
                    els.status.style.opacity = '1';
                    break;
            }
        }

        function toggleOverlay(show) {
            state.isActive = show;
            if (show) {
                // Show Overlay
                els.overlay.classList.remove('opacity-0', 'pointer-events-none');
                els.startScreen.classList.add('opacity-0', 'scale-90');
                
                // Start Listening
                try { state.recognition.start(); } catch(e){}
            } else {
                // Hide Overlay
                els.overlay.classList.add('opacity-0', 'pointer-events-none');
                els.startScreen.classList.remove('opacity-0', 'scale-90');
                
                // Stop Everything
                state.recognition.stop();
                state.synth.cancel();
                state.isProcessing = false;
            }
        }

        // --- Listeners ---
        els.btnStart.addEventListener('click', () => toggleOverlay(true));
        els.btnClose.addEventListener('click', () => toggleOverlay(false));

        // Start
        init();

    </script>
</body>
</html>